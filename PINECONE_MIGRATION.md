# üîÑ Pinecone Migration Guide

H∆∞·ªõng d·∫´n chi ti·∫øt v·ªÅ vi·ªác migrate d·ªØ li·ªáu l√™n Pinecone Vector Database

## üìã T·ªïng quan

Project n√†y s·ª≠ d·ª•ng **Pinecone** l√†m vector database ƒë·ªÉ l∆∞u tr·ªØ v√† t√¨m ki·∫øm th√¥ng tin du l·ªãch. D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi th√†nh embeddings v√† upload l√™n Pinecone index.

## üèóÔ∏è Ki·∫øn tr√∫c Pinecone

```
Azure OpenAI Embeddings ‚Üí Pinecone Index ‚Üí RAG Search ‚Üí GPT Response
```

### Th√†nh ph·∫ßn ch√≠nh:

1. **PineconeRAGSystem**: Class qu·∫£n l√Ω k·∫øt n·ªëi v√† operations v·ªõi Pinecone
2. **Azure OpenAI Embeddings**: T·∫°o vector embeddings t·ª´ text
3. **Pinecone Index**: L∆∞u tr·ªØ vectors v√† metadata
4. **RAG Query**: T√¨m ki·∫øm v√† t·∫°o context cho GPT

## üöÄ B∆∞·ªõc 1: Chu·∫©n b·ªã Pinecone

### 1.1. T·∫°o Pinecone Account

1. Truy c·∫≠p: https://www.pinecone.io
2. ƒêƒÉng k√Ω t√†i kho·∫£n mi·ªÖn ph√≠
3. T·∫°o project m·ªõi

### 1.2. C·∫•u h√¨nh Index

```python
# Index configuration
{
    "name": "travel-agency",
    "dimension": 1536,  # text-embedding-3-small dimension
    "metric": "cosine",
    "cloud": "aws",
    "region": "us-east-1"
}
```

### 1.3. L·∫•y API Credentials

Trong Pinecone Console:
- V√†o **API Keys** tab
- Copy **API Key**
- Note **Environment** v√† **Index Name**

## üîß B∆∞·ªõc 2: C·∫•u h√¨nh Project

### 2.1. Environment Variables

Trong file `.env`:

```env
# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=travel-agency
PINECONE_CLOUD=aws
PINECONE_REGION=us-east-1

# Azure OpenAI cho Embeddings
AZURE_OPENAI_EMBEDDING_API_KEY=your_embedding_key
AZURE_OPENAI_EMBEDDING_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_EMBED_MODEL=text-embedding-3-small
```

### 2.2. Ki·ªÉm tra k·∫øt n·ªëi

```bash
# Test Pinecone connection
python scripts/test_pinecone_connection.py
```

Script n√†y s·∫Ω ki·ªÉm tra:
- ‚úÖ DNS resolution
- ‚úÖ HTTPS connectivity  
- ‚úÖ Pinecone API authentication
- ‚úÖ Index access

## üìä B∆∞·ªõc 3: Migration Scripts

### 3.1. Generate Sample Data

```bash
# T·∫°o v√† upload d·ªØ li·ªáu m·∫´u
python scripts/generate_sample_data.py
```

**D·ªØ li·ªáu m·∫´u bao g·ªìm**:
- **10 t·ªânh th√†nh**: H√† N·ªôi, TP.HCM, ƒê√† N·∫µng, Nha Trang, ƒê√† L·∫°t, Hu·∫ø, H·ªôi An, Sapa, Ph√∫ Qu·ªëc, C·∫ßn Th∆°
- **3 categories**: Attractions, Foods, Hotels
- **~90 records** t·ªïng c·ªông

### 3.2. Data Structure

M·ªói record trong Pinecone c√≥ c·∫•u tr√∫c:

```json
{
  "id": "hanoi_attraction_1",
  "values": [0.1, 0.2, ...],  // 1536-dimension embedding
  "metadata": {
    "text": "H·ªì Ho√†n Ki·∫øm l√† bi·ªÉu t∆∞·ª£ng c·ªßa H√† N·ªôi...",
    "location": "H√† N·ªôi",
    "category": "attraction",
    "name": "H·ªì Ho√†n Ki·∫øm",
    "description": "H·ªì n∆∞·ªõc ng·ªçt t·ª± nhi√™n...",
    "rating": 4.8,
    "price_range": "free"
  }
}
```

### 3.3. Upload Process

Script `generate_sample_data.py` th·ª±c hi·ªán:

1. **T·∫°o d·ªØ li·ªáu m·∫´u** t·ª´ `PROVINCES_DATA`
2. **Generate embeddings** qua Azure OpenAI
3. **Sanitize metadata** cho Pinecone format
4. **Batch upload** (100 records/batch)
5. **Verification** v√† b√°o c√°o k·∫øt qu·∫£

```python
# Core upload logic
for record in records:
    # Get embedding
    embedding = rag_system.get_embedding(record["text"])
    
    # Sanitize metadata
    metadata = rag_system._sanitize_metadata(record["metadata"])
    metadata["text"] = record["text"]
    
    # Upsert to Pinecone
    rag_system.index.upsert([(record["id"], embedding, metadata)])
```

## üîç B∆∞·ªõc 4: Verification

### 4.1. Ki·ªÉm tra Index Stats

```bash
# Trong Python console
from src.pinecone_rag_system import PineconeRAGSystem

rag = PineconeRAGSystem()
stats = rag.get_index_stats()
print(f"Total vectors: {stats['total_vectors']}")
```

### 4.2. Test Search

```python
# Test search functionality
results = rag.search("H√† N·ªôi du l·ªãch", top_k=5)
for doc in results:
    print(f"ID: {doc['id']}, Score: {doc['score']:.3f}")
    print(f"Text: {doc['text'][:100]}...")
```

### 4.3. Test RAG Query

```python
# Test full RAG pipeline
result = rag.query("G·ª£i √Ω ƒë·ªãa ƒëi·ªÉm du l·ªãch ·ªü H√† N·ªôi")
print("Answer:", result['answer'])
print("Sources:", result['sources'])
```

## üõ†Ô∏è B∆∞·ªõc 5: Custom Data Upload

### 5.1. JSON Format

ƒê·ªÉ upload d·ªØ li·ªáu t√πy ch·ªânh, t·∫°o file JSON v·ªõi format:

```json
[
  {
    "id": "unique_id_1",
    "text": "Text content ƒë·ªÉ t·∫°o embedding v√† t√¨m ki·∫øm",
    "metadata": {
      "location": "T√™n ƒë·ªãa ƒëi·ªÉm",
      "category": "attraction|food|hotel",
      "name": "T√™n c·ª• th·ªÉ",
      "description": "M√¥ t·∫£ chi ti·∫øt",
      "rating": 4.5,
      "price_range": "budget|mid|luxury"
    }
  }
]
```

### 5.2. Upload Custom Data

```python
# Upload t·ª´ JSON file
from src.pinecone_rag_system import PineconeRAGSystem

rag = PineconeRAGSystem()
success = rag.load_data_to_index("path/to/your/data.json")
print(f"Upload successful: {success}")
```

### 5.3. Upload qua Streamlit UI

1. Ch·∫°y app: `streamlit run app.py`
2. V√†o **Knowledge Base** tab
3. Upload JSON file qua interface
4. Ki·ªÉm tra k·∫øt qu·∫£ upload

## üìà Performance Tuning

### 5.1. Batch Size

```python
# Trong generate_sample_data.py
batch_size = 100  # Adjust based on data size v√† API limits
```

### 5.2. Embedding Model

```env
# Trong .env file
AZURE_OPENAI_EMBED_MODEL=text-embedding-3-small  # 1536 dimensions
# Ho·∫∑c text-embedding-3-large cho quality cao h∆°n (3072 dimensions)
```

### 5.3. Search Parameters

```python
# Trong PineconeRAGSystem.query()
min_score = 0.5      # Minimum similarity threshold
top_k = 5           # Number of documents to retrieve
```

## üö® Troubleshooting

### Connection Issues

```bash
# Test t·ª´ng b∆∞·ªõc
python scripts/test_pinecone_connection.py
```

**L·ªói th∆∞·ªùng g·∫∑p**:
- **API Key invalid**: Ki·ªÉm tra key trong Pinecone console
- **Index not found**: T·∫°o index v·ªõi ƒë√∫ng t√™n v√† c·∫•u h√¨nh
- **Dimension mismatch**: ƒê·∫£m b·∫£o index dimension = embedding model dimension
- **Rate limiting**: Gi·∫£m batch size ho·∫∑c th√™m delay

### Data Issues

```python
# Ki·ªÉm tra d·ªØ li·ªáu uploaded
stats = rag.get_index_stats()
print(f"Current vector count: {stats['total_vectors']}")

# Test search
results = rag.search("test query")
print(f"Search returned {len(results)} results")
```

### Performance Issues

```python
# Monitor search latency
import time
start = time.time()
results = rag.search("query")
print(f"Search took {time.time() - start:.3f}s")
```

## üîÑ Maintenance

### Regular Tasks

1. **Monitor usage**: Ki·ªÉm tra Pinecone dashboard
2. **Update data**: Upload d·ªØ li·ªáu m·ªõi ƒë·ªãnh k·ª≥
3. **Clean old data**: X√≥a d·ªØ li·ªáu c≈© n·∫øu c·∫ßn
4. **Backup**: Export data n·∫øu c·∫ßn thi·∫øt

### Index Management

```python
# X√≥a t·∫•t c·∫£ vectors (c·∫©n th·∫≠n!)
rag.delete_all_vectors()

# Ki·ªÉm tra index stats
stats = rag.get_index_stats()
```

## üìö Resources

- **Pinecone Docs**: https://docs.pinecone.io
- **Azure OpenAI Embeddings**: https://docs.microsoft.com/azure/cognitive-services/openai/
- **Project Repository**: https://github.com/Elevate-AI-Room-7/workshop-final

---

*Migration completed! üéâ*